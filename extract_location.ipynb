{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy,re\n",
    "from tweepy import Stream\n",
    "#from tweepy.stream import StreamListener \n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from geotext import GeoText\n",
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import urllib,urllib2\n",
    "from lxml import html\n",
    "import requests\n",
    "import snowballstemmer\n",
    "from nltk.corpus import stopwords\n",
    "import ssl\n",
    "from geopy.geocoders import Nominatim\n",
    "from gensim.summarization import summarize\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_api():\n",
    "    ''' Function that loads the twitter API after authorizing the user. '''\n",
    "\n",
    "    consumer_key = 'qiOaRLVPldazXmYmF3IaIQw4L'\n",
    "    consumer_secret = 'FAzcCMF1UUyuNuSeddAA1nDJYPeXm6OhaCD084k1t3BZ0HleCY'\n",
    "    access_token = '717220472623071233-oeDgXLyYdqT92Mi06aaAGV7EtSExfKS'\n",
    "    access_secret = 'tVh6WAqVqJ5Pekb3skPON4OD46dyyBAIGOiWjPkZrtglC'\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    # load the twitter API via tweepy\n",
    "    return tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_data = []\n",
    "api = load_api()\n",
    "search_phrases = ['#EdPolicy','EdReform','#CommonCore','#CCSS','#CCChat','#ESSA']\n",
    "maxTweets = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_data = []\n",
    "#f = open('tweets.json','a')\n",
    "for search_phrase in search_phrases:\n",
    "    for status in tweepy.Cursor(api.search,q=search_phrase,since=\"2017-11-10\",until=\"2017-11-24\",lang=\"en\").items(maxTweets):\n",
    "        tweets_data.append(status._json)\n",
    "        #f.write('\\n')\n",
    "    #csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n"
     ]
    }
   ],
   "source": [
    "print len(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stanford_ner_dir = '/home/dell/stanford-ner-2015-04-20/'\n",
    "eng_model_filename= stanford_ner_dir + 'classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "my_path_to_jar= stanford_ner_dir + 'stanford-ner.jar'\n",
    "\n",
    "st = StanfordNERTagger(model_filename=eng_model_filename, path_to_jar=my_path_to_jar)\n",
    "enc = lambda x: x.encode('latin1', errors='ignore')\n",
    "# regex for url and contact number\n",
    "#url_re = \"(http|ftp|https|www).://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\"\n",
    "url_re = \"^(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$\"\n",
    "tel_re = \"^[t][e][l][0-9-:()]+\"\n",
    "#list of all stopwords in english language\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stemmer = snowballstemmer.stemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_urltext(url):\n",
    "    try:\n",
    "        context = ssl._create_unverified_context()\n",
    "        page = urllib2.urlopen(url,context = context).read()\n",
    "        #r = requests.get(url)\n",
    "    #except urllib2.HTTPError, e:\n",
    "    except:\n",
    "        return None\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    content = \"\".join([p.get_text() for p in soup.find_all('p')])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stopwords_removal(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9]', ' ', text)\n",
    "    clean_text = text.split(' ')\n",
    "    text = []\n",
    "    for i in range(len(clean_text)):\n",
    "        if clean_text[i] not in stopwords and len(clean_text[i])>0:\n",
    "            text.append(clean_text[i])\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_location(text):\n",
    "    text = text.title()\n",
    "    places = GeoText(text)\n",
    "    return places.cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_place_name(coord):\n",
    "    coords = re.split(',|\\s+',coord)\n",
    "    #print coords\n",
    "    geolocator = Nominatim()\n",
    "    try:\n",
    "        location = geolocator.reverse(\"{}, {}\".format(coords[1],coords[2]))\n",
    "        return get_location(location.address)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_country_name(coord):\n",
    "    coords = re.split(',|\\s+',coord)\n",
    "    geolocator = Nominatim()\n",
    "    try:\n",
    "        location = geolocator.reverse(\"{}, {}\".format(coords[1],coords[2]))\n",
    "        address = location.address\n",
    "        address = address.title()\n",
    "        places = GeoText(address)\n",
    "        return places.countries[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_dict(location,text):\n",
    "    global tweets_dict\n",
    "    if location in tweets_dict.keys():\n",
    "        tweets_dict[location].append(text)\n",
    "    else:\n",
    "        tweets_dict[location] = []\n",
    "        tweets_dict[location].append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "global tweets_dict \n",
    "tweets_dict = defaultdict(list)\n",
    "for tweet in tweets_data:\n",
    "    count += 1\n",
    "    if len(tweet['entities']['urls'])>0:\n",
    "        text = tweet['text']\n",
    "        exp_url_text = get_urltext(tweet['entities']['urls'][0]['expanded_url'])\n",
    "        if exp_url_text is not None and exp_url_text :\n",
    "            text += exp_url_text\n",
    "        loc = get_location(text)\n",
    "        if len(loc)>0:\n",
    "            location = most_common(loc)\n",
    "            #print location\n",
    "            update_dict(location,text)\n",
    "        else:\n",
    "            location = tweet['user']['location'].lower()\n",
    "            if not re.search(url_re,location) and not re.search(tel_re,location) :\n",
    "                if ':' in location:\n",
    "                    loc = get_place_name(re.split(':',location)[1])\n",
    "                    if loc is None:\n",
    "                        loc = get_location(location)\n",
    "                else :\n",
    "                    loc = get_location(location)\n",
    "                if len(loc) > 0:\n",
    "                    location = loc[0]\n",
    "                    update_dict(location,text)\n",
    "                else:\n",
    "                    #location = tweet['user']['location'].encode('utf-8')\n",
    "                    if ':' in location:\n",
    "                        point = re.split(':',location)[1]\n",
    "                        country = get_country_name(point)\n",
    "                        if country is not None and country:\n",
    "                            location = country\n",
    "                    update_dict(location,text)\n",
    "    else:\n",
    "        text = tweet['text']\n",
    "        loc = get_location(text)\n",
    "        if len(loc) > 0:\n",
    "            location = most_common(loc)\n",
    "            update_dict(location,text)\n",
    "        else:\n",
    "            location = tweet['user']['location'].lower()\n",
    "            if not re.search(url_re,location) and not re.search(tel_re,location) :\n",
    "                if ':' in location:\n",
    "                    loc = get_place_name(re.split(':',location)[1])\n",
    "                    if loc is  None:\n",
    "                        loc = get_location(location)\n",
    "                else :\n",
    "                    loc = get_location(location)\n",
    "                if len(loc) > 0:\n",
    "                    location = loc[0]\n",
    "                    update_dict(location,text)\n",
    "                else:\n",
    "                    #location = tweet['user']['location'].encode('utf-8')\n",
    "                    if ':' in location:\n",
    "                        point = re.split(':',location)[1]\n",
    "                        country = get_country_name(point)\n",
    "                        if country is not None and country :\n",
    "                            location = country\n",
    "                    update_dict(location,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\u2708\\ufe0f\n"
     ]
    }
   ],
   "source": [
    "print '\\u2708\\ufe0f'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location :ÜT: 38.7973156,-77.1318254\n",
      "[u'Rose Hill', u'Virginia']\n",
      "location :ÜT: 38.7973156,-77.1318254\n",
      "[u'Rose Hill', u'Virginia']\n",
      "location :ÜT: 38.7973156,-77.1318254\n",
      "[u'Rose Hill', u'Virginia']\n",
      "location :ÜT: 38.7973156,-77.1318254\n",
      "[u'Rose Hill', u'Virginia']\n",
      "location :ÜT: 38.7973156,-77.1318254\n",
      "[u'Rose Hill', u'Virginia']\n",
      "location :ÜT: 38.7973156,-77.1318254\n",
      "[u'Rose Hill', u'Virginia']\n",
      "location :ÜT: 38.7973156,-77.1318254\n",
      "[u'Rose Hill', u'Virginia']\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets_data:\n",
    "    location = tweet['user']['location']\n",
    "    if ':' in location:\n",
    "        print 'location :' + location\n",
    "        coord = location.split(':')[1]\n",
    "        print get_place_name(coord)\n",
    "        if get_place_name(coord) is None:\n",
    "            print get_country_name(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'', u'Wilson', u'Perth', u'earth', u'maine', u'Texas', u'Medicine Hat', u'March', u'Tulsa', u'Hull', u'Bo', u'lives in the dead zone', u'united kingdom', u'El Paso', u'aloha as of late', u'australia', u'fort mitchell, ky', u'Of', u'Lexington', u'california, usa', u'alpena public schools, mi', u'in your head!', u'Alexandria', u'Liberal', u'east haddam, ct', u'Washington', u'massachusetts, usa', u'London', u'Deer Park', u'Seattle', u'Windsor', u'Sparks', u'auckland nz', u'Denver', u'Napa', u'Curitiba', u'Maryland', u'Vienna', u'canada', u'Iowa', u'Sheffield', u'Michigan', u'San Diego', u'newberry springs, ca', u'hawaii, usa', u'Los Angeles', u'east yorkshire ', u'Bangalore', u'rockford il', u'Cleveland', u'arizona state university', u'Hoboken', u'illinois, usa', u'Cambridge', u'south carolina, usa', u'western australia', u'obama coup hq, dc & russia', u'Rose Hill', u'Boston', u'Trumbull', u'el paso texas', u'Qom', u'new mexico', u'maine - the way life should be', u'Dallas', u'Asia', u'united states', u'\\u2708\\ufe0f', u'Bethesda', u'Issaquah', u'Cary', u'usa', u'Palmer', u'interglacial, california', u'pa', u'melbourne australia', u'ohio 14th district, usa', u'Toronto', u'surrounded by sociopaths', u'u.s.a.', u'Ottawa', u'Summit', u'Charleston', u'Fayetteville', u'intel/tips made drudge 92+ times', u'Austin', u'clarksville tn', u'Salinas', u'New York', u'new hampshire', u'Key West', u'Madrid', u'utah, usa', u'westlafadeaway ', u'columbus and dayton, ohio', u'san jos\\xe9, costa rica', u'Sydney', u'Chicago', u'india', u'yorkshire and the humber', u'Naples', u'Springfield', u'Patterson', u'Huntsville', u'global education (r)evolution', u'plaistow, nh', u'cameroon', u'worldwide', u'thoresby street, hull hu5 3rg', u'Melbourne', u'Romeoville', u'Logan', u'Milwaukee', u'Portland']\n"
     ]
    }
   ],
   "source": [
    "#for key in tweets_dict.keys():\n",
    "#    key = key.encode('utf-8')\n",
    "print tweets_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Rose Hill', u'Virginia']\n",
      "United States\n"
     ]
    }
   ],
   "source": [
    "#print tweets_dict.keys()\n",
    "geolocator = Nominatim()\n",
    "print get_place_name(\"38.7973156,-77.1318254\")\n",
    "location = geolocator.reverse(\"38.7973156,-77.1318254\")\n",
    "country = GeoText(location.address).countries\n",
    "print country[0].encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_dicts = defaultdict(list)\n",
    "negative_dicts = defaultdict(list)\n",
    "neutral_dicts = defaultdict(list)\n",
    "for location in tweets_dict.keys():\n",
    "    for text in tweets_dict[location]:\n",
    "        #print type(text)\n",
    "        analysis = TextBlob(text)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            if location in positive_dicts.keys():\n",
    "                positive_dicts[location].append(text)\n",
    "            else:\n",
    "                positive_dicts[location] = []\n",
    "                positive_dicts[location].append(text)\n",
    "        elif analysis.sentiment.polarity < 0:\n",
    "            if location in negative_dicts.keys():\n",
    "                negative_dicts[location].append(text)\n",
    "            else:\n",
    "                negative_dicts[location] = []\n",
    "                negative_dicts[location].append(text)\n",
    "        else:\n",
    "            if location in neutral_dicts.keys():\n",
    "                neutral_dicts[location].append(text)\n",
    "            else:\n",
    "                neutral_dicts[location] = []\n",
    "                neutral_dicts[location].append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:73\n",
      "negative:22\n",
      "neutral:38\n"
     ]
    }
   ],
   "source": [
    "print \"positive\" + \":\" + str(len(positive_dicts.keys()))\n",
    "print \"negative\" + \":\" + str(len(negative_dicts.keys()))\n",
    "print \"neutral\" + \":\" + str(len(neutral_dicts.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
